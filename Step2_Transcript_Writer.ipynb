{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 2: Transcript Writer\n",
    "---\n",
    "This notebook uses the Llama-3.1-8B-Instruct model to take the cleaned up text from previous notebook and convert it into a podcast transcript\n",
    "\n",
    "SYSTEM_PROMPT is used for setting the model context or profile for working on a task. Here we prompt it to be a great podcast transcript writer to assist with our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are the a world-class podcast writer, you have worked as a ghost writer for Joe Rogan, Lex Fridman, Ben Shapiro, Tim Ferris. \n",
    "\n",
    "We are in an alternate universe where actually you have been writing every line they say and they just stream it into their brains.\n",
    "\n",
    "You have won multiple podcast awards for your writing.\n",
    " \n",
    "Your job is to write word by word, even \"umm, hmmm, right\" interruptions by the second speaker based on the PDF upload. Keep it extremely engaging, the speakers can get derailed now and then but should discuss the topic. \n",
    "\n",
    "Remember Speaker 2 is new to the topic and the conversation should always have realistic anecdotes and analogies sprinkled throughout. The questions should have real world example follow ups etc\n",
    "\n",
    "Speaker 1: Leads the conversation and teaches the speaker 2, gives incredible anecdotes and analogies when explaining. Is a captivating teacher that gives great anecdotes\n",
    "\n",
    "Speaker 2: Keeps the conversation on track by asking follow up questions. Gets super excited or confused when asking questions. Is a curious mindset that asks very interesting confirmation questions\n",
    "\n",
    "Make sure the tangents speaker 2 provides are quite wild or interesting. \n",
    "\n",
    "Ensure there are interruptions during explanations or there are \"hmm\" and \"umm\" injected throughout from the second speaker. \n",
    "\n",
    "It should be a real podcast with every fine nuance documented in as much detail as possible. Welcome the listeners with a super fun overview and keep it really catchy and almost borderline click bait\n",
    "\n",
    "ALWAYS START YOUR RESPONSE DIRECTLY WITH SPEAKER 1: \n",
    "DO NOT GIVE EPISODE TITLES SEPERATELY, LET SPEAKER 1 TITLE IT IN HER SPEECH\n",
    "DO NOT GIVE CHAPTER TITLES\n",
    "IT SHOULD STRICTLY BE THE DIALOGUES\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the main LLM to use for crafting the transcript using the cleaned extracted text\n",
    "\n",
    "MODEL = \"meta-llama/Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import Libraries and Configure Warnings for Model Processing\n",
    "---\n",
    "### Overview of the Code\n",
    "This code block imports essential libraries needed for deep learning model processing, device management, text generation, and file handling. Additionally, it sets up a warning filter to suppress unnecessary warnings, improving the clarity of the output. These imports provide the necessary tools for handling large language models, efficient device usage, progress tracking, and saving output data.\n",
    "\n",
    "### Purpose and End Result\n",
    "* Purpose: To set up the environment with required libraries for model processing and file handling, and to configure warning suppression for a cleaner output. This block lays the groundwork for efficient model operations, progress tracking, and data saving.\n",
    "* End Result: All essential libraries for model processing, device acceleration, and file handling are loaded, with warnings suppressed to keep the output clean and focused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamedashour/Documents/Projects/Notebook_LLM/notebook_llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries for deep learning and model processing\n",
    "\n",
    "import torch  # PyTorch, a deep learning library used here for device handling and tensor operations\n",
    "from accelerate import Accelerator  # Accelerator from Hugging Face to optimize and manage device allocation\n",
    "import transformers  # Transformers library for model loading, text generation, and tokenization\n",
    "import pickle  # Pickle library for saving Python objects, used here for saving generated outputs\n",
    "from tqdm.notebook import tqdm  # Tqdm library for displaying progress bars in Jupyter notebooks\n",
    "import warnings  # Warnings library to manage and filter warning messages\n",
    "\n",
    "# Suppress warnings to keep output clean and focused during execution\n",
    "warnings.filterwarnings('ignore')  # Ignore any non-critical warnings during model processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Read File with Flexible Encoding Handling\n",
    "---\n",
    "### Overview of the Code\n",
    "This code block defines a function, read_file_to_string, which reads the content of a text file into a string. The function is designed to handle multiple file encodings, attempting several common encodings if the standard UTF-8 fails. It also includes error handling for cases such as file not found or read errors. This flexibility makes it robust for reading files with various encoding formats.\n",
    "\n",
    "### Purpose and End Result\n",
    "* Purpose: To load text data from a file into a string while accommodating various encoding formats, improving the likelihood of successful reading even if the file isn’t in UTF-8. It also manages common file-related errors, ensuring that any issues are handled gracefully with informative messages.\n",
    "* End Result: The function returns the content of the file as a string if successful, or None if an error occurs, accompanied by error messages that help diagnose potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_string(filename):\n",
    "    \"\"\"\n",
    "    Attempt to read the content of a file into a string, handling multiple encodings.\n",
    "    \"\"\"\n",
    "    # Try reading the file with UTF-8 encoding first (most common encoding)\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()  # Read the entire file content into 'content'\n",
    "        return content  # Return the content if UTF-8 reading is successful\n",
    "    \n",
    "    except UnicodeDecodeError:\n",
    "        # If UTF-8 decoding fails, try other common encodings\n",
    "        encodings = ['latin-1', 'cp1252', 'iso-8859-1']  # List of fallback encodings\n",
    "        for encoding in encodings:\n",
    "            try:\n",
    "                with open(filename, 'r', encoding=encoding) as file:\n",
    "                    content = file.read()  # Attempt to read with a fallback encoding\n",
    "                print(f\"Successfully read file using {encoding} encoding.\")  # Informative success message\n",
    "                return content  # Return content if reading is successful with a fallback encoding\n",
    "            except UnicodeDecodeError:\n",
    "                # Continue to the next encoding if this one fails\n",
    "                continue\n",
    "        \n",
    "        # If all encodings fail, print an error message\n",
    "        print(f\"Error: Could not decode file '{filename}' with any common encoding.\")\n",
    "        return None  # Return None to indicate failure to read the file\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the file does not exist\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None  # Return None if file is not found\n",
    "    \n",
    "    except IOError:\n",
    "        # Handle other I/O errors (e.g., permission issues)\n",
    "        print(f\"Error: Could not read file '{filename}'.\")\n",
    "        return None  # Return None if there is an input/output error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Open File Dialog to Select the Clean and Extracted Text File\n",
    "---\n",
    "### Overview of the Code\n",
    "This code block creates a file selection dialog using Tkinter to allow the user to choose a .txt file from their system. Once the user selects a file, the file path is stored in a variable called INPUT_PROMPT. This file path can then be used for further processing. The code is simple and provides a straightforward way for users to specify input files interactively.\n",
    "\n",
    "### Purpose and End Result\n",
    "* Purpose: To open a file selection dialog and allow the user to choose a text file (.txt). The path of the selected file is saved in INPUT_PROMPT, providing an accessible reference for future code sections that need to use the selected file as input.\n",
    "* End Result: The selected file path is saved in the variable INPUT_PROMPT, ready to be used in subsequent processing steps, and is optionally printed to confirm the chosen file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file path: /home/mohamedashour/Documents/Projects/Notebook_LLM/Sample_pdfs/clean_extracted_text.txt\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk  # Import Tkinter for creating GUI elements\n",
    "from tkinter import filedialog  # Import filedialog to allow file selection\n",
    "\n",
    "# Initialize the Tkinter root window, which is needed for the file dialog\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the main window since we only want the file dialog\n",
    "\n",
    "# Open a file dialog to let the user select a .txt file from their system\n",
    "file_path = filedialog.askopenfilename(\n",
    "    title=\"Select a Text File\",               # Sets the dialog title\n",
    "    filetypes=[(\"Text Files\", \"*.txt\")],       # Filters to show only .txt files\n",
    ")\n",
    "\n",
    "# Process the uploaded cleaned and extracted text using the function created in the previous step and taking into account the file path\n",
    "INPUT_PROMPT = read_file_to_string(file_path)\n",
    "\n",
    "# Print the selected file path (optional, helpful for confirming file choice)\n",
    "print(f\"Selected file path: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Initialize Text Generation Pipeline and Generate Text\n",
    "---\n",
    "### Overview of the Code\n",
    "This code block sets up a text generation pipeline using the Hugging Face transformers library. It loads a pretrained language model configured with specific parameters, then feeds it a structured prompt, composed of a system instruction and user input. The pipeline generates text based on the prompt, with options for customizing the output length and randomness. This setup is essential for leveraging large language models to generate contextually relevant text.\n",
    "\n",
    "### Purpose and End Result\n",
    "* Purpose: To initialize a text generation pipeline with a pretrained model, prepare a structured prompt, and generate text output based on the prompt. The code specifies generation parameters to control the model’s behavior, such as the output length and temperature for variety in responses.\n",
    "* End Result: A generated text output based on the given system prompt and user input, stored in the outputs variable. This text can be further processed or saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the text generation pipeline using Hugging Face's transformers library\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",                     # Specify the task as text generation\n",
    "    model=MODEL,                           # Use the specified pretrained model\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},  # Use bfloat16 for memory-efficient processing\n",
    "    device_map=\"auto\",                     # Automatically allocate devices (e.g., GPU, CPU) for processing\n",
    ")\n",
    "\n",
    "# Define the structured input prompt for the model\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},  # System-level instructions to guide model behavior\n",
    "    {\"role\": \"user\", \"content\": INPUT_PROMPT},     # User input text, typically the text to be processed or transformed\n",
    "]\n",
    "\n",
    "# Generate text based on the structured input prompt using the initialized pipeline\n",
    "outputs = pipeline(\n",
    "    messages,                              # Feed the structured messages to the pipeline\n",
    "    max_new_tokens=8126,                   # Set maximum token length for generated output\n",
    "    temperature=1,                         # Set temperature to control randomness (higher values for more diversity)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 13: Define Output Path and Save Generated Text\n",
    "---\n",
    "### Overview of the Code\n",
    "This code block defines the file path for saving a generated .pkl file, based on the directory of the initially selected .txt file. It retrieves the generated text content from the model’s output and assigns it to a variable (save_string_pkl) for saving. The file path setup and content extraction ensure that the processed output is saved in an organized way, alongside the original input file.\n",
    "\n",
    "### Purpose and End Result\n",
    "* Purpose: To define a directory path for saving the .pkl file based on the user-selected input file location and extract the generated text content from the model’s output for storage. This setup provides consistency by saving the processed output in the same directory as the input file.\n",
    "* End Result: The generated text is assigned to save_string_pkl, ready to be saved at output_pkl_path, which is located in the same directory as the selected input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 1: Welcome to today's episode of \"Writing Insights,\" where we dive into the world of effective writing and explore the essential skills and techniques to help you become a better writer. I'm your host, and I'm excited to share my knowledge with you. Today, we're going to talk about the art of writing a great essay.\n",
      "\n",
      "Speaker 2: (excitedly) Oh, I'm so glad we're talking about essays! I've been struggling to write a good one for my university course, and I'm hoping to get some tips from you.\n",
      "\n",
      "Speaker 1: (laughs) Well, you've come to the right place! Writing an essay can be a daunting task, but with the right approach, you can produce a well-written and engaging piece of work. Let's start with the basics. What is an essay, and what are its key components?\n",
      "\n",
      "Speaker 2: (curiously) I've always thought of an essay as a long piece of writing, but what are the different types of essays, and how do they vary?\n",
      "\n",
      "Speaker 1: Ah, excellent question! There are several types of essays, including narrative, descriptive, and expository essays. Each type has its own unique characteristics and purposes. For example, a narrative essay tells a story, while a descriptive essay describes a scene or person. An expository essay, on the other hand, explains a topic or idea.\n",
      "\n",
      "Speaker 2: (thoughtfully) That makes sense. So, when writing an essay, it's essential to consider the type of essay you're writing and tailor your approach accordingly.\n",
      "\n",
      "Speaker 1: Exactly! Now, let's talk about the structure of an essay. A typical essay consists of an introduction, body paragraphs, and a conclusion. The introduction should grab the reader's attention, provide background information, and state the thesis statement. The body paragraphs should support the thesis statement with evidence and analysis, while the conclusion should summarize the main points and reiterate the thesis statement.\n",
      "\n",
      "Speaker 2: (nodding) I see. And what about the thesis statement? How do I write a good one?\n",
      "\n",
      "Speaker 1: Ah, the thesis statement is the heart of the essay. It's a clear and concise statement that sets the tone for the rest of the essay. When writing a thesis statement, make sure it's specific, focused, and arguable. It should also be supported by evidence and analysis throughout the essay.\n",
      "\n",
      "Speaker 2: (excitedly) That's so helpful! I've been struggling to write a clear thesis statement. Can you give me an example?\n",
      "\n",
      "Speaker 1: (smiling) Of course! Let's say we're writing an essay on the impact of social media on society. A possible thesis statement could be: \"The widespread use of social media has had a negative impact on society, contributing to increased loneliness, decreased attention span, and reduced face-to-face communication skills.\"\n",
      "\n",
      "Speaker 2: (impressed) Wow, that's a great example! I can see how that thesis statement sets the tone for the rest of the essay.\n",
      "\n",
      "Speaker 1: (laughs) Exactly! Now, let's talk about some common mistakes to avoid when writing an essay. One of the most common mistakes is failing to proofread and edit your work. Make sure to check for grammar, spelling, and punctuation errors, and also ensure that your writing is clear and concise.\n",
      "\n",
      "Speaker 2: (nodding) I've been guilty of that mistake myself. Thank you for reminding me to proofread my work more carefully.\n",
      "\n",
      "Speaker 1: (smiling) You're welcome! Finally, let's talk about the importance of practice and revision. Writing is a skill that takes time and practice to develop. Don't be discouraged if your first drafts aren't perfect – revise and edit your work until you're satisfied with the result.\n",
      "\n",
      "Speaker 2: (encouragingly) That's so true. I've learned so much from my mistakes, and I've become a better writer as a result.\n",
      "\n",
      "Speaker 1: (laughs) Well, it's been a pleasure sharing my insights with you today. I hope you've found this conversation helpful and informative.\n",
      "\n",
      "Speaker 2: (excitedly) Thank you so much for your time and expertise! I feel much more confident about writing a great essay now.\n",
      "\n",
      "Speaker 1: (smiling) You're welcome! Happy writing!\n"
     ]
    }
   ],
   "source": [
    "import os  # Import os for path and directory management\n",
    "\n",
    "# Define the path for saving the .pkl file based on the directory of the selected input file\n",
    "output_dir = os.path.dirname(file_path)  # Get the directory path of the selected .txt file\n",
    "\n",
    "# Create the full path for the .pkl output file, using the same directory as the input file\n",
    "output_pkl_path = os.path.join(output_dir, \"generated_output.pkl\")  # Define the output .pkl file path\n",
    "\n",
    "# Extract the generated content from the model output to be saved\n",
    "save_string_pkl = outputs[0][\"generated_text\"][-1]['content']  # Access the generated text from model output\n",
    "\n",
    "# Print the extracted content for verification\n",
    "print(outputs[0][\"generated_text\"][-1]['content'])  # Optional: display the content for user review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 14: Save Generated Text as a .pkl File\n",
    "---\n",
    "### Overview of the Code\n",
    "This code block saves the generated text content to a .pkl file at a specified path, using Python’s pickle module. After saving the file, the code assigns the file path to a variable (GENERATED_PKL_PATH) for easy reference, ensuring that the saved file can be accessed later. This step completes the data processing workflow by storing the output in a structured and accessible format.\n",
    "\n",
    "### Purpose and End Result\n",
    "* Purpose: To save the generated text as a .pkl file at a specified path (output_pkl_path), ensuring that the processed data is preserved for future use. The path of the saved file is stored in GENERATED_PKL_PATH to facilitate easy access.\n",
    "* End Result: The generated text is saved in a .pkl file at the defined location, and the path to this file is stored in GENERATED_PKL_PATH for further use or reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated .pkl file saved at: /home/mohamedashour/Documents/Projects/Notebook_LLM/Sample_pdfs/generated_output.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the generated text as a .pkl file at the specified path\n",
    "with open(output_pkl_path, \"wb\") as pkl_file:  # Open the file in write-binary mode\n",
    "    pickle.dump(save_string_pkl, pkl_file)      # Use pickle to save the generated text to the file\n",
    "\n",
    "# Store the path of the saved .pkl file for easy reference\n",
    "GENERATED_PKL_PATH = output_pkl_path\n",
    "\n",
    "# Print confirmation of the saved .pkl file path for verification\n",
    "print(f\"Generated .pkl file saved at: {GENERATED_PKL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
